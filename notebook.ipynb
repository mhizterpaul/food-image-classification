{"cells":[{"source":"# Food Image Classification with Hugging Face\n\n<p align=\"center\">\n  <img src=\"Food class_2.png\" alt=\"Food class_2\" width=\"500\">\n</p>\n\nA popular social media platform dedicated to food enthusiasts wants to improve user engagement by adding advanced image recognition features. As a machine learning engineer, you are tasked with developing a food image classification system using Hugging Face's state-of-the-art models. This system will automatically identify and categorize food items in user-uploaded photos, allowing for better content organization and personalized food content recommendations.\n\nYour responsibility is to develop a robust food category image classification system using pre-trained models from Hugging Face.\n\nThe goal is to enhance user interaction by providing accurate food classification, enabling users to easily find and engage with content related to their favorite foods, and improving the overall experience on the platform.\n\nIn this dynamic project, we leverage the power of PyTorch and transformers, utilizing an open-source model from Hugging Face as the backbone of our solution.","metadata":{"tags":[]},"id":"35d4e17b-eeb6-40dd-a140-7b949390e115","cell_type":"markdown"},{"source":"# Install required libraries\n!pip install matplotlib\n!pip install pillow\n!pip install scikit-learn\n!pip install transformers datasets evaluate\n!pip install torchvision","metadata":{"outputsMetadata":{"0":{"height":598,"type":"stream"},"1":{"height":440,"type":"stream"},"2":{"height":59,"type":"stream"},"3":{"height":440,"type":"stream"},"4":{"height":227,"type":"stream"},"5":{"height":440,"type":"stream"}},"executionCancelledAt":null,"executionTime":16110,"lastExecutedAt":1730836196498,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install required libraries\n!pip install matplotlib\n!pip install pillow\n!pip install scikit-learn\n!pip install transformers datasets evaluate\n!pip install torchvision","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"173b3336-4aa6-4baf-a709-211ab1fb4fa2","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.6.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.0.6)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.37.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.23.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (9.2.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.9.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.29.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\nRequirement already satisfied: evaluate in /home/repl/.local/lib/python3.8/site-packages (0.4.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.8.17)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (7.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.5.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.13)\nRequirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2022.7.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.10.15)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.6.3)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import required libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport evaluate\nfrom PIL import Image\nfrom datasets import load_dataset\nfrom transformers import pipeline\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, RandomResizedCrop, ColorJitter, ToTensor, CenterCrop, Compose, Normalize\nfrom transformers.utils import logging\n# Only show error messages from the transformers library to reduce the amount of log output\nlogging.set_verbosity_error()\n\nimport warnings\n# Ignore all Python warnings to keep the output clean\nwarnings.filterwarnings(\"ignore\")","metadata":{"executionCancelledAt":null,"executionTime":205,"lastExecutedAt":1730836196703,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport evaluate\nfrom PIL import Image\nfrom datasets import load_dataset\nfrom transformers import pipeline\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, RandomResizedCrop, ColorJitter, ToTensor, CenterCrop, Compose, Normalize\nfrom transformers.utils import logging\n# Only show error messages from the transformers library to reduce the amount of log output\nlogging.set_verbosity_error()\n\nimport warnings\n# Ignore all Python warnings to keep the output clean\nwarnings.filterwarnings(\"ignore\")","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"id":"4aad9185","cell_type":"code","execution_count":4,"outputs":[]},{"source":"# Helper function to convert image to RGB format\ndef convert_to_rgb(image):\n    \"\"\"\n    Converts an image to RGB format.\n\n    Parameters:\n    image (PIL.Image): An image object.\n\n    Returns:\n    PIL.Image: Image object in RGB format.\n    \"\"\"\n    return image.convert('RGB')","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1730836196755,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Helper function to convert image to RGB format\ndef convert_to_rgb(image):\n    \"\"\"\n    Converts an image to RGB format.\n\n    Parameters:\n    image (PIL.Image): An image object.\n\n    Returns:\n    PIL.Image: Image object in RGB format.\n    \"\"\"\n    return image.convert('RGB')"},"id":"aac5b2f0-ea99-4853-887d-27522c3e903c","cell_type":"code","execution_count":5,"outputs":[]},{"source":"#load the dataset\nfood = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\nfood = food.train_test_split(test_size=0.2)\n\n","metadata":{"executionCancelledAt":null,"executionTime":505,"lastExecutedAt":1730836197260,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#load the dataset\nfood = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\nfood = food.train_test_split(test_size=0.2)\n\n","outputsMetadata":{"1":{"height":101,"type":"stream"},"17":{"height":101,"type":"stream"}}},"cell_type":"code","id":"01f5eb4a-d95a-4222-a541-d08c942934c9","outputs":[],"execution_count":6},{"source":"#proprocess and the dataset\nfrom transformers import AutoImageProcessor\n\nmodel_name = \"google/vit-base-patch16-224-in21k\"\nimage_processor = AutoImageProcessor.from_pretrained(model_name)\n\n# Define the size based on the image processor\nsize = ( image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size else (image_processor.size[\"height\"], image_processor.size[\"width\"]) )\n\n# Define the transformations \n_transforms = Compose([ CenterCrop(size), ToTensor(), Normalize(mean=image_processor.image_mean, std=image_processor.image_std) ])","metadata":{"executionCancelledAt":null,"executionTime":135,"lastExecutedAt":1730836197397,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#proprocess and the dataset\nfrom transformers import AutoImageProcessor\n\nmodel_name = \"google/vit-base-patch16-224-in21k\"\nimage_processor = AutoImageProcessor.from_pretrained(model_name)\n\n# Define the size based on the image processor\nsize = ( image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size else (image_processor.size[\"height\"], image_processor.size[\"width\"]) )\n\n# Define the transformations \n_transforms = Compose([ CenterCrop(size), ToTensor(), Normalize(mean=image_processor.image_mean, std=image_processor.image_std) ])"},"cell_type":"code","id":"eeb7683a-c7e4-47d1-b10e-5c6430cef081","outputs":[],"execution_count":7},{"source":"# Apply the transformations \ndef transforms(samples): \n    samples[\"pixel_values\"] = [_transforms(convert_to_rgb(img)) for img in samples[\"image\"]] \n    del samples[\"image\"] \n    return samples\n\nfood = food.with_transform(transforms)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1730836197453,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Apply the transformations \ndef transforms(samples): \n    samples[\"pixel_values\"] = [_transforms(convert_to_rgb(img)) for img in samples[\"image\"]] \n    del samples[\"image\"] \n    return samples\n\nfood = food.with_transform(transforms)"},"cell_type":"code","id":"e4052451-8690-455e-97e7-4872382cdc8d","outputs":[],"execution_count":8},{"source":"#Data Augmentation on training set and test set\n# Define the data augmentation transformations for the training set\ntrain_data_augmentation = Compose([\n    RandomHorizontalFlip(),\n    RandomRotation(degrees=(-10, 10)),\n    RandomResizedCrop(size=size, scale=(0.8, 1.2)),\n])\n\n\n# Apply the transformations to the datasets\nfood[\"train\"].transform = train_data_augmentation\n","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1730836197501,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Data Augmentation on training set and test set\n# Define the data augmentation transformations for the training set\ntrain_data_augmentation = Compose([\n    RandomHorizontalFlip(),\n    RandomRotation(degrees=(-10, 10)),\n    RandomResizedCrop(size=size, scale=(0.8, 1.2)),\n])\n\n\n# Apply the transformations to the datasets\nfood[\"train\"].transform = train_data_augmentation\n"},"cell_type":"code","id":"f4a90c3d-94bb-4b45-a6c7-927c1a35081e","outputs":[],"execution_count":9},{"source":"labels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1730836197553,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"labels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label"},"cell_type":"code","id":"162ac3be-bca6-4ce5-bd49-a84bec6e32bc","outputs":[],"execution_count":10},{"source":"from transformers import AutoModelForImageClassification\n\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"executionCancelledAt":null,"executionTime":2692,"lastExecutedAt":1730836200245,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from transformers import AutoModelForImageClassification\n\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)"},"cell_type":"code","id":"75657cab-fdd8-4479-9768-67f630def6de","outputs":[],"execution_count":11},{"source":"from sklearn.metrics import accuracy_score\nimport numpy as np\nfrom transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": accuracy_score(labels, predictions)}\n","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1730836200296,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import accuracy_score\nimport numpy as np\nfrom transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": accuracy_score(labels, predictions)}\n"},"cell_type":"code","id":"068e1ae7-f7a8-4613-b1b3-f67e37659ac0","outputs":[],"execution_count":12},{"source":"from transformers import  TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./food_model_result\",\n    remove_unused_columns=False,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=food[\"train\"],\n    eval_dataset=food[\"test\"],\n    tokenizer=image_processor,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"executionCancelledAt":null,"executionTime":144,"lastExecutedAt":1730836342215,"lastExecutedByKernel":"0bd87aa5-827a-4a6a-8cb6-349c6451d676","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"f41ad1d8-cc53-4728-88bd-061c20f2e198","outputs":[],"execution_count":0},{"source":"local_path = \"./fine_tuned_food_model\"\ntrainer.save_model(local_path)","metadata":{"executionCancelledAt":1730835093551},"cell_type":"code","id":"6e65c4ce-da9d-40b9-9fb8-057aacefefbb","outputs":[],"execution_count":null}],"metadata":{"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}