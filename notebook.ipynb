{"cells":[{"cell_type":"markdown","id":"35d4e17b-eeb6-40dd-a140-7b949390e115","metadata":{"tags":[]},"source":["# Food Image Classification with Hugging Face\n","\n","<p align=\"center\">\n","  <img src=\"./food_class_2.png\" alt=\"Food class_2\" width=\"500\">\n","</p>\n","\n","A popular social media platform dedicated to food enthusiasts wants to improve user engagement by adding advanced image recognition features. As a machine learning engineer, you are tasked with developing a food image classification system using Hugging Face's state-of-the-art models. This system will automatically identify and categorize food items in user-uploaded photos, allowing for better content organization and personalized food content recommendations.\n","\n","Your responsibility is to develop a robust food category image classification system using pre-trained models from Hugging Face.\n","\n","The goal is to enhance user interaction by providing accurate food classification, enabling users to easily find and engage with content related to their favorite foods, and improving the overall experience on the platform.\n","\n","In this dynamic project, we leverage the power of PyTorch and transformers, utilizing an open-source model from Hugging Face as the backbone of our solution.\n"]},{"cell_type":"code","execution_count":3,"id":"173b3336-4aa6-4baf-a709-211ab1fb4fa2","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":16110,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1730836196498,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install required libraries\n!pip install matplotlib\n!pip install pillow\n!pip install scikit-learn\n!pip install transformers datasets evaluate\n!pip install torchvision","outputsMetadata":{"0":{"height":598,"type":"stream"},"1":{"height":440,"type":"stream"},"2":{"height":59,"type":"stream"},"3":{"height":440,"type":"stream"},"4":{"height":227,"type":"stream"},"5":{"height":440,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.6.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.37.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.23.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.2.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (9.2.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.9.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.29.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\n","Requirement already satisfied: evaluate in /home/repl/.local/lib/python3.8/site-packages (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.8.17)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (7.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.5.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2022.7.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.10.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.14.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.6.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["# Install required libraries\n","!pip install matplotlib\n","!pip install pillow\n","!pip install scikit-learn\n","!pip install transformers datasets evaluate\n","!pip install torchvision"]},{"cell_type":"code","execution_count":4,"id":"4aad9185","metadata":{"executionCancelledAt":null,"executionTime":205,"lastExecutedAt":1730836196703,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport evaluate\nfrom PIL import Image\nfrom datasets import load_dataset\nfrom transformers import pipeline\nfrom torchvision.transforms import RandomHorizontalFlip, RandomRotation, RandomResizedCrop, ColorJitter, ToTensor, CenterCrop, Compose, Normalize\nfrom transformers.utils import logging\n# Only show error messages from the transformers library to reduce the amount of log output\nlogging.set_verbosity_error()\n\nimport warnings\n# Ignore all Python warnings to keep the output clean\nwarnings.filterwarnings(\"ignore\")","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"outputs":[],"source":["# Import required libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import evaluate\n","from PIL import Image\n","from datasets import load_dataset\n","from transformers import pipeline\n","from torchvision.transforms import RandomHorizontalFlip, RandomRotation, RandomResizedCrop, ColorJitter, ToTensor, CenterCrop, Compose, Normalize\n","from transformers.utils import logging\n","# Only show error messages from the transformers library to reduce the amount of log output\n","logging.set_verbosity_error()\n","\n","import warnings\n","# Ignore all Python warnings to keep the output clean\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":5,"id":"aac5b2f0-ea99-4853-887d-27522c3e903c","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1730836196755,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Helper function to convert image to RGB format\ndef convert_to_rgb(image):\n    \"\"\"\n    Converts an image to RGB format.\n\n    Parameters:\n    image (PIL.Image): An image object.\n\n    Returns:\n    PIL.Image: Image object in RGB format.\n    \"\"\"\n    return image.convert('RGB')"},"outputs":[],"source":["# Helper function to convert image to RGB format\n","def convert_to_rgb(image):\n","    \"\"\"\n","    Converts an image to RGB format.\n","\n","    Parameters:\n","    image (PIL.Image): An image object.\n","\n","    Returns:\n","    PIL.Image: Image object in RGB format.\n","    \"\"\"\n","    return image.convert('RGB')"]},{"cell_type":"code","execution_count":6,"id":"01f5eb4a-d95a-4222-a541-d08c942934c9","metadata":{"executionCancelledAt":null,"executionTime":505,"lastExecutedAt":1730836197260,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#load the dataset\nfood = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\nfood = food.train_test_split(test_size=0.2)\n\n","outputsMetadata":{"1":{"height":101,"type":"stream"},"17":{"height":101,"type":"stream"}}},"outputs":[],"source":["#load the dataset\n","food = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\n","food = food.train_test_split(test_size=0.2)\n","\n"]},{"cell_type":"code","execution_count":7,"id":"eeb7683a-c7e4-47d1-b10e-5c6430cef081","metadata":{"executionCancelledAt":null,"executionTime":135,"lastExecutedAt":1730836197397,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#proprocess and the dataset\nfrom transformers import AutoImageProcessor\n\nmodel_name = \"google/vit-base-patch16-224-in21k\"\nimage_processor = AutoImageProcessor.from_pretrained(model_name)\n\n# Define the size based on the image processor\nsize = ( image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size else (image_processor.size[\"height\"], image_processor.size[\"width\"]) )\n\n# Define the transformations \n_transforms = Compose([ CenterCrop(size), ToTensor(), Normalize(mean=image_processor.image_mean, std=image_processor.image_std) ])"},"outputs":[],"source":["#proprocess and the dataset\n","from transformers import AutoImageProcessor\n","\n","model_name = \"google/vit-base-patch16-224-in21k\"\n","image_processor = AutoImageProcessor.from_pretrained(model_name)\n","\n","# Define the size based on the image processor\n","size = ( image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size else (image_processor.size[\"height\"], image_processor.size[\"width\"]) )\n","\n","# Define the transformations \n","_transforms = Compose([ CenterCrop(size), ToTensor(), Normalize(mean=image_processor.image_mean, std=image_processor.image_std) ])"]},{"cell_type":"code","execution_count":8,"id":"e4052451-8690-455e-97e7-4872382cdc8d","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1730836197453,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Apply the transformations \ndef transforms(samples): \n    samples[\"pixel_values\"] = [_transforms(convert_to_rgb(img)) for img in samples[\"image\"]] \n    del samples[\"image\"] \n    return samples\n\nfood = food.with_transform(transforms)"},"outputs":[],"source":["# Apply the transformations \n","def transforms(samples): \n","    samples[\"pixel_values\"] = [_transforms(convert_to_rgb(img)) for img in samples[\"image\"]] \n","    del samples[\"image\"] \n","    return samples\n","\n","food = food.with_transform(transforms)"]},{"cell_type":"code","execution_count":9,"id":"f4a90c3d-94bb-4b45-a6c7-927c1a35081e","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1730836197501,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Data Augmentation on training set and test set\n# Define the data augmentation transformations for the training set\ntrain_data_augmentation = Compose([\n    RandomHorizontalFlip(),\n    RandomRotation(degrees=(-10, 10)),\n    RandomResizedCrop(size=size, scale=(0.8, 1.2)),\n])\n\n\n# Apply the transformations to the datasets\nfood[\"train\"].transform = train_data_augmentation\n"},"outputs":[],"source":["#Data Augmentation on training set and test set\n","# Define the data augmentation transformations for the training set\n","train_data_augmentation = Compose([\n","    RandomHorizontalFlip(),\n","    RandomRotation(degrees=(-10, 10)),\n","    RandomResizedCrop(size=size, scale=(0.8, 1.2)),\n","])\n","\n","\n","# Apply the transformations to the datasets\n","food[\"train\"].transform = train_data_augmentation\n"]},{"cell_type":"code","execution_count":10,"id":"162ac3be-bca6-4ce5-bd49-a84bec6e32bc","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1730836197553,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"labels = food[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label"},"outputs":[],"source":["labels = food[\"train\"].features[\"label\"].names\n","label2id, id2label = dict(), dict()\n","for i, label in enumerate(labels):\n","    label2id[label] = str(i)\n","    id2label[str(i)] = label"]},{"cell_type":"code","execution_count":11,"id":"75657cab-fdd8-4479-9768-67f630def6de","metadata":{"executionCancelledAt":null,"executionTime":2692,"lastExecutedAt":1730836200245,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from transformers import AutoModelForImageClassification\n\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)"},"outputs":[],"source":["from transformers import AutoModelForImageClassification\n","\n","\n","model = AutoModelForImageClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(labels),\n","    id2label=id2label,\n","    label2id=label2id,\n",")"]},{"cell_type":"code","execution_count":12,"id":"068e1ae7-f7a8-4613-b1b3-f67e37659ac0","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1730836200296,"lastExecutedByKernel":"d945688e-a382-4dcf-961d-1156d7d76a63","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import accuracy_score\nimport numpy as np\nfrom transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": accuracy_score(labels, predictions)}\n"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","import numpy as np\n","from transformers import DefaultDataCollator\n","\n","data_collator = DefaultDataCollator()\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return {\"accuracy\": accuracy_score(labels, predictions)}\n"]},{"cell_type":"code","execution_count":0,"id":"f41ad1d8-cc53-4728-88bd-061c20f2e198","metadata":{"executionCancelledAt":null,"executionTime":144,"lastExecutedAt":1730836342215,"lastExecutedByKernel":"0bd87aa5-827a-4a6a-8cb6-349c6451d676","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"outputs":[],"source":["from transformers import  TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./food_model_result\",\n","    remove_unused_columns=False,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=16,\n","    gradient_accumulation_steps=4,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=food[\"train\"],\n","    eval_dataset=food[\"test\"],\n","    tokenizer=image_processor,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"6e65c4ce-da9d-40b9-9fb8-057aacefefbb","metadata":{"executionCancelledAt":1730835093551},"outputs":[],"source":["local_path = \"./fine_tuned_food_model\"\n","trainer.save_model(local_path)"]}],"metadata":{"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
